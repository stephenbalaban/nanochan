Got a question too small for its own thread? Ask away!  Remember anons, there are no stupid questions.
UDP is a way/format for sending data without error correction, but faster?  yes, because you can ignore missing packets and stuff like which is nice for some applications because TCP will always automatically do a big complicated dance of resending stuff when something was missing on the other hand, UDP packets are mostly raw IP packets that drop in all mixed up and incomplete with bytes that are wrong and all that so you mostly need to do some stuff to check if they are correct    Apart from that are they essentialy the same beast?  uhm, yeah, i guess.    How/why do things like Retroshare connect in several ways - how does a firewall stop one type of connection but not others?  peer to peer networking is somewhat complex, but basically you have a local client which will ask remote clients for a connection and therefore your pc's firewall and your router will know the connection is desired there are not really types of connections outside TCP and UDP and other protocols or stuff built on top of them, only port numbers    I'm just kinda wanting tips and confirmation or direction in my understanding of these things… am i missing somthing fundermental? I'm trying to get my head round all this and have been looking things up - but everytime you get dumped with pages and pages of waaay to indepth detail about things…  any good links covering these kind of basic questions, without getting too overwhelmed?  the important part is the first part, that the internet is just data packets stuffed into each other
correction, TCP doesnt do sessions, only streams. so when the data is over the wire it stops.   https://en.wikipedia.org/wiki/Transmission_Control_Protocol   HTTP version 1.1 does sessions. it keeps in touch with the website for a while so that they don't have to do the TCP and HTTP handshake stuff again when you click a link or something
another correction:   ethernet adress.  i meant MAC ADRESS of course which was my whole point. ARGH
Thank you Anon  Much respect!
UDP packets are mostly raw IP packets that drop in all mixed up and incomplete with bytes that are wrong and all that so you mostly need to do some stuff to check if they are correct  I was under the impression that UDP did include basic error detection, and would discard corrupt packets.   https://en.wikipedia.org/wiki/User_Datagram_Protocol#Checksum_computation  It has a 16bit checksum.
This thread is for learning about and writing compilers: Translation from one language to another and optimization.  Please post if you're creating one, studying it or interested in collaboration!
Bootstrapping: *  https://rwmj.wordpress.com/2010/08/07/jonesforth-git-repository/  *  http://homepage.ntlworld.com/edmund.grimley-evans/bcompiler.html  *  http://piumarta.com/software/maru/  *  https://github.com/darius/ichbins  *  http://churchturing.org/y/90-min-scc.pdf   Virtual machines/bytecode: *  http://morepypy.blogspot.co.uk/2011/04/tutorial-writing-interpreter-with-pypy.html  *  http://www.cs.nott.ac.uk/~gmh/ccc.pdf  *  http://llvm.org/docs/tutorial/  *  http://wambook.sourceforge.net/ 
tiny C compilers:  One more:  https://github.com/rui314/8cc 
Thank you so much for these!  I would love to collaborate on one.
We should try to discuss stuff a bit. I'm a beginner in this area but I've learned a lot since I started.  Has anyone found anything interesting from those links? Or are you looking into something else that could be good to talk about - any stuff you've made you'd like to share and maybe explain?     5047  Yeah that would be great! we'll have to work out details somehow.
I was just reading a cool paper today about the \"compiler optimization correctness gap\".  Basically stuff like scrubbing out passwords from memory can sometimes be removed by compiler optimizations.. so it's hard to write secure code with optimizations on.   http://nebelwelt.net/publications/15LangSec/ 
Hi Lainons, I'm going to try writing some imageboard software over the next week or so and was wondering if you could help me compile a list of things that it MUST(required features)  have and a a list of what it SHOULD have (not necessary features but good ones).  I'll start:  MUST HAVE:   board creation    greentext     IDs     image duplication check    banning   SHOULD HAVE:   live post updating    webm/other file upload   Thanks in advance, Lainons!
MUST:   name and trips    email (sage, noko)    subject    post links (  1234)    cross-board links (   /cyb/1234)    password to delete your own post and/or image    image upload    rangeban    cute mascot   SHOULD HAVE:   catalog    pages    /recent and /all    oekaki    spoiler    some markup maybe    capcodes for bitheads/admins    SXML API 
are you going to do that in lisp? man you beat me to it (no I wasn't realy going to do it) Anyway Must:    catalog  Should:   dice rolls    spoiler/code and probably some other interesting markups    nationality flags    content customization (hide, pin, etc)    CSS customization 
Flags are nice.
List stuff you'd like to see happen but feel too lazy/inexperienced to make yourself at the moment. Stuff you think someone else might find interesting as a side project to play around with. I'll start:  -Forum censor based on language translation systems instead of a simple find   replace. -Web directory based on booru style tagging instead of categories. Could just use booru.org and post links as screencaps/comments but that seems unwieldy.
Yes, like that, but not Lisp, y prefer a more friendly lang, like Python, Ruby or Lua.
Common Lisp isn't the easiest thing to get into. The source code might help you make one in Python, or you could just get the code to compile to another language.
First you need to choose a rendering and templating method based on the features you want on the IB. That is server-side or client-side or hybrid; Backbone with string concatenation, simple string concatenation or some other templating library. The choices from thereon largely depend on this.
I'd like to try to make a small flying drone with a thermal camera that hovers around the house at night. If it detects a thermal signature between some set parameters it flies over to the thing, takes a photo, and wirelessly uploads the photo to cloud storage.
I'm just trying to think of good ideas to separate what's possible from what's currently easy to do.
Hello Lains! I'm currently in the zone writing my first android app. It's a school project, a helpful app that reminds you to do your everyday life stuff (groceries and stuff). What about you? Have you made any apps?
i have meddled with making android apps, but it was too java.  also constructing user interfaces seemed pretty ass backwards to me, if i had to make an android app i'd use a webview since i know css and so on  what's also pretty elegant is just installing an app icon that opens a mobile web site or something, it's lightweight, supports all kinds of features via whatever browser the user chooses and so on.
I don't write apps, but I've written a little tool for something similar before.
Is there anything that you can't do right now that you wish you could? Maybe that you're working towards overall? In relation to programming/coding of course.   I wish that overall, I had a better grasp on large applications and how everything worked together. I can get lost in them sometimes.
I'm in with you guys. Someone make a thread.
See, but then I have to have a really good grasp of sexps and list in general. I could whip something up but with the experience I currently have it would be half-baked at best and not even functioning at worst.  I just need to practice more, and finish my SICP, but it'll take time.
I really have an interest in p2p soykaf, security (like jails, chroots, grsec soykaf, not skiddie botnet soykaf) and ai  I can barely fuarrrking write a fizzbuzz though
Basically everything. I focus too much on academic concepts and far too little on \"real world\" problems. Of the things I want to learn, these stick out (at the moment): I want to know how servers are programmed and how to build a website, how to build web applications, how to program with graphics and build games (either offline or online), etc. I dunno about the first 2 but I should probably pick up Lua again and try Löve.
but I should probably pick up Lua again and try Löve.  That's a good idea.
When you want to contribute to a project, how do you go about familierizing yourself with how the program works?
I think this approach is helpful:  http://www.gigamonkeys.com/code-reading/ 
Step 1: Find the entry point.
I find that trying to fix a bug gets me to focus and understand it in a way that just trying to \"read it\" doesn't.
When I want to modify a program from someone else, I start searching for a keyword or a string related to the function that I want to modify, and then study the function call tree, associated classes and structures, and so on.
I'm kinda curious. I'm a beggining programmer and I'm reading an O'reilly linux system programming, an a C++ game ai book as well. So what do YOU guys do? gamedev? webdev? nixdev? AI? cryptography? uber 1337? I'm really curious
python makes sense when you're shuffling bytes and soykaf
years ago it would have been Perl. Everyone in netsec has about the same basic programming skillset.  Popular scripting language , C, and  assembly for most popular arch . x86_64 ASM is on my todo list. ARM Assembly will be a pretty big deal soon too.
How does one get familiar with Assembly?
not the security guy but it's quite easy, check out any random tutorial or example on how assembly programs look and work, learn how the commands are called in whatever assembly language you want to learn (e.g. MOV ), and you're done?   so basically you have registers in which the numbers you're adding together or whatever are loaded from the memory using some command, and then some command like ADD R1, R1, R2 causes register 1 and register 2 to be added and the result to be stored in R1.. i don't remember how the x86 stuff was named because i recently had to learn ARM assembly.   loops and conditions in assembly are done with jump labels or what the things are called, it's basically a bunch of GOTOs.  some of them check if some register is zero or something like that, there is a lot of them so it kind of depends what you're doing.
(cont)  http://www.cs.virginia.edu/~evans/cs216/guides/x86.html  something like this should help
New programmers are always welcome on /λ/. Keep in mind that, in accordance with the rules, questions and discussion about the best ways to start learning programming belong in this thread, the Beginner General.  Typical starting languages:  Python: useful as a first language, good for short scripts and other quick hacks. Also present in a few popular web frameworks such as Flask and Django.  Javascript: the only client-side scripting language for web sites, Javascript is also used in some server applications with the Node.js framework.  Java: an Oracle monstrosity, Java is unfortunately is the only language available if you wish to write Android apps.  PHP: the de facto tried-and-true language for web backends. Any aspiring web developer, like it or not, must learn this.  Sane languages: Python Lisp/Scheme C  Resources for learning:  http://openbookproject.net/thinkcs/python/english3e/   http://eloquentjavascript.net/code/   https://developer.android.com/training/index.html   http://php.net/manual/en/tutorial.php   http://learnlispthehardway.org/   http://c.learncodethehardway.org/book/   http://learnyouahaskell.com/   https://mitpress.mit.edu/sicp/   http://www.codecademy.com/   And for the adventurous:  http://www.wiley.com/WileyCDA/WileyTitle/productCd-0470497025.html 
Use the project, which means writing code if the project is a library and means using the application if the project is standalone. If a project is big enough, there will be an overview of the structure and substructures available somewhere. Read it. Once you know how the project is used and the architecture of the design, you'll know the context each section of code lives in and how each sections effects the rest of the application. If you're working on a Model View Controller application and you change a view, models will not be effected. Knowing this allows you to reason about views without worrying about how they effect models, because they don't.  The book \"The Architecture of Open Source Applications\" contains 49 overviews of open source projects; such as Bash, Eclipse, and even Battle of Wesnoth.  http://aosabook.org/en/index.html   To understand a project, first understand how to use it, then the architecture, and finally the source code of individual parts.
I agree. Make this a seperate thread please. I think it should be covered in more detail.
It usually takes a few sessions of getting to know the program. First by tracing some functionality starting from main, stopping where I don't get it. of course this means looking at the function definitions elsewhere. Then I run the program and try to see if this gives me any clue on what's going on. If it doesn't I regard mystery code as voodoo magic and move on trying to make sense of the whole thing rather than it's peculiarities
So I finished several courses on codeacademy.com, which were goods to refresh my rusty baby skills in php but didn't teach me nothing new beside the basics of OOP. What kind of good documentation is available on the wired to learn to design more complex things?   This must be one of the most documented programming language online, but it seems there is a lot of security traps, obsolete implementations or tutorials teaching bad practices. I don't know what to choose. So I know the official documentation of course,  http://www.phptherightway.com , but if you have something else in mind, I would be glad to chickitawt
Make this a seperate thread please  Done     5032 
Moved from    /tech/2873  What are you currently working on?
Sorry, bad naming choices, for \"convertUnit\" read \"getRatio\ \"convertLength\" read \"lengthRatio\", and \"convertMass\" read \"massRatio\".",
Thanks you sensei, that will be a great way to learn how to use custom data type
that's so cool! nice idea
I've been working on a programming challenge list that I found on /g/. I've worked through the first four or five, and it's a fun little programming project that I can work on daily.
Alright lain let's design a lisp. Why? well for fun. Besides, we all dislike *some* aspect of whatever lisp we are  using so, why not get together and try to agree on a lisp with which most people can be happy? Who knows, if everything goes well we might even implement and make it lain's official lisp dialect.  What features would make the perfect lisp? lisp-1 or lisp-2? (I'll vote for 1) typed? lazy? object system? hygienic macros enforced? continuations? what else?  I'd too suggest that there be some facility to \"glue\" programs from other dialects for true portability. Though I can't think of a good way to do it now. Any ideas?
\"PyLISP\"      ;; parentheses     (+ (f 1 2 3))     (+ (f 1 2) 3)     (+ (f 1) 2 3)     (+ f 1 2 3)      ;; whitespace     + f         1 2 3       + f         1 2       3      + f         1       2       3      + f 1 2 3
Pylisp      ;; parentheses (+ (f 1 2 3)) (+ (f 1 2) 3) (+ (f 1) 2 3) (+ f 1 2 3)  ;; whitespace +   f 1 2 3 +   f     1 2   3 +   f     1   2   3 +   f 1 2 3   
Can we not?  Significant whitespace is the bane of good design.
Check Wart for a Lisp with Python-like keyword args and significant whitespace.   https://github.com/akkartik/wart 
I started a programming study group recently on 8ch's /tech/ board, with  moderate success. I figured there might be more people interested in /λ/.  The idea is to keep ourselves motivated by taking courses together and helping it each other as we go.  Our IRC channel, #learnprog on Freenode, has an average of ~12 people idling, most of which are people who already know how to code and aren't really taking any courses. I'm hoping to attract more beginners here, but more experienced people are welcome too.  Make sure to join the IRC if you're interested. We have a document with more information on ongoing courses, projects, and such.  The thread on 8ch:  https://8ch.net/tech/res/97725.html 
https://www.edx.org/course/introduction-computational-thinking-data-mitx-6-00-2x-0   This one has just started. It's beginner-intermediate with a focus on data science. Anyone wants to take it with me?
Im taking it. I took the first half of the course and I think it was great.
Cool. I thought it was great too. I didn't want to do this one before, but I changed my mind because I liked the previous.  Wouldn't you be interested in joining me on IRC for this one?
Yeah! I'd love to get in touch with you. I am not a big IRC user,tho. Should we start our own room or something?  Also, this part of the course kinda looks easier than the first part. What do you think?  Maybe is just because I am familiar with Stats and the concepts they presented.
I'd love to get in touch with you.   Sweet! I've been hoping to find someone around my level to be a continuous study partner. Maybe it will work out between us?    Should we start our own room or something?   I'm the OP. You can use the #learnprog channel I made.    Also, this part of the course kinda looks easier than the first part. What do you think?    Maybe is just because I am familiar with Stats and the concepts they presented.   I haven't completed the final 6.00.1 test yet. I will start 6.00.2 once I'm done with that. I don't have the stats background, so let's see.
Let's discuss coding on vintage computers. Has any Lainon done some work on old '80s Apples, Ataris, Amigas? Do you still hack around on old hardware? Share your experiences past and present in here.
Err Atari ST = 1985  . 16/32bit!
this seems really fun but I have no clue how to get started   http://blog.attractmo.de/post/111642896790/this-is-just-the-beginning-of-what-we-can-do-on 
I recently took possession of an old ass iMac  What can I do with it?
you could install a the ppc netbsd port. modern linuxes tend to run like complete ass on older macs. there is also this neat amigaOS clone  http://www.morphos.de/  but it slows down to a near halt after 30 minutes of use to encourage you to buy a license. runs really fast when its operating normally and there is nothing stopping you from rebooting over and over since you can just run it off a live-cd.
My first suggestion would be to turn it into a gerbil cage. It looks like it takes a lot of energy, and lots of space as well. For recycling older computers, I'd take something less bulky and generically upgradable.
Lainchain programmers, what programming language is best for computational science? It's been a few years since I've programmed but I've retained most of what I learned in C.
Python+SciPy is very powerful for computational science. So is Julia, R, and Octave. If you're willing to pay money (or pirate non-free software), MATLAB is extremely powerful.   I would recommend using one of the above languages for the overall code and embedding C just for the bits that need to be most efficient. Also remember that SciPy and MATLAB both benefit from BLAS, an extremely powerful linear algebra library. Julia is also supposed to be pretty efficient.
A friend uses fortran at work, and he's always bitching about bugs in gfortran, so I guess so.
gcc is what I use at home to learn. For actual simulations and such I would use the NAG compiler with all the fancy libraries. Haven't had to do much with it yet though.
Is there any meaningful difference besides the instruction sets?     4966    Yes, x86 is ComplexInstructionSetComputing while ARM is ReducedInstructionSetComputing    Just pointing out something
Python will you give you access to the scipy/numpy/pandas stack. Any CPU intensive code can be written in C/Cython (or god forbid Fortran) and easily wrapped.  Julia is an interesting newcomer, but I don't know of anyone who uses it for serious projects yet.  Haskell and all JVM suggestions are simply ridiculous.
I've been working as a developer for 7 years.  I lead a small team of developers, writing mostly RoR apps and PHP-based ecommerce sites.  I make more money than my peers and enjoy my work, but feel like I've hit a ceiling.  Should I go back to school and finish my CS degree (barely started it), or just beef the soykaf out of my Github?  Which route would help me make more scratch?
What ceiling do you feel you hit exactly?  I would think that any intelligent employer would, while taking note of your lack of degree, see how much experience you have and what you've done in the past, and feel that you're a good hire.  This is assuming all the stuff you've written wasn't garbage.
even though i have absolutely no experience in any industry i agree with    4992  and think an employer would look at the fact you've actually been working and producing projects instead of a piece of paper.
I understand that you would assume random anon is full of garbage, but I'm not. It's often hard to show what your real involvement in a project was to a new employer. I think you are proving why I should work more on making my public Github repositories better.  To address your question, I feel I'm hitting a salary cap. According to salary-comparison sites, I'm making more than most in my industry and location, but I guess I'll need to work remotely or move to a bigger tech hub to make more money.     4994  Our industry is one that a degree is useful, but not absolutely necessary. Not all industries are that way.
am i the only one who got a lot of problems with colors, design and layout?   holy fuarrrk, i can't pick color schemes neither know how to use them in the right place. any help on that?
I too, suck hairy donkey balls at co-ordinating colours. Back when I did more web stuff I just scraped  http://www.colourlovers.com/  for ideas.
Try this    http://paletton.com/#uid=70u0u0kFzoorEyOALtIL2jGR9e3   Note you have colour design for 1, 2 ,3 and 4 colour layouts.
i'm good with colors, i like them. picking an abstract color scheme can be hard, use one of the tools presented and do lots of iterations and trial error. everyone does.  oh, very importantly, find cool looking.. websites or whatever and steal colors, color combinations, etc. from them, try understanding why it looks good, try to copy it e.g. in red-ish instead of greenish like it was, etc.   the shorthand #123 (=#112233) is really useful to me for quickly trying out stuff
Take a screen grab abd just fill stuff in photoshop (errr if you have it?) select colours using wand but have contiguous checked off   very quick and easy to select colours and find right combination using a proper colour picker! - once found colours you like - ref the HEX number!  very veyr real time and intuative way of doing colour - a coding interface is not so intuative/fast.  Gimp probably has a select colour function at least (will do fine) and might even have a similar tool to the magic wand but for wand to work it must have somthing like the contiguious option avalible???
Hi there Lainons, I have just been enrolled into Bachelor of IT, I'm quite new to programming languages however I am keen to learn.    I've been teaching myself C/C++ and I already know how to do some basic things in Visual basic, besides that I have made websites for highschool projects using my own knowledge of HTML and CSS, I am also a user of loonix (you know that illegal hacker operating system?).  I have poked around with my raspberry pi, hacked my school (lulz) and I build custom ROMS for my phone.  Yes I have installed Gentoo  .  IT WAS SO FUN.  Discuss Newbie tips for programming and such, or your experience starting out with programming and learning.    I purchased the book \"the C programming language\ I use it a bit, not as much as I should though.   On my shortlist of programming languages to learn are: Python, Java, C, LISP, RUBY, SQL and PHP. (I'm aware Python is a scripting language.)",
There are existing threads for this.    (I'm aware Python is a scripting language.)  This triggers my autism. That doesn't mean anything. It's still a programming language, and there's more than one implementation.
Could it be that commenting your code interferes with learning how to read code?  are there any other best practices that might have negative consequences?
http://www.gigamonkeys.com/code-reading/ 
Only if you write bad comments. Comments should be the why, whereas the code is the how.
Anyone know of a good cable modem (Docsis 3.0 channel-bonding) that can be uncapped.  looking for something like the old SB5100 days.
https://lainchan.org/tech/res/5166.html 
what do you guys think of lua?
ah, yeah, but it's fixed now? cool.
Check out this too:  http://firestr.com/  Fire★, a P2P application platform that you can extend with Lua!
Lua is an escaped configuration language and it feels like it. No real arrays, tables indexed at one. Ugh.  It does have TCO and JIT though 
I actually started using Lua this week, in order to make some widgets for awesomeWM. For those who like tiling WMs, awesome is very friendly to extend.
tables indexed at one  oh right that's when i stopped looking into lua last time i tried.
Has anyone here designed a social networking website? What were the steps necessary to create it?
Do you know how to do frontend? Like HTML5, JS, CSS, React, Ember, etc?  The language on backend is irrelevant
what is that pic from? the number gets me nowhere, reverse image search gets me nowhere and picture has name \"sphere clipart\" wtf?
I'm fluent in HTML5, CSS and Javascript. For backend I was thinking of using Ruby.     4919  hxxp://8ch.net/32/res/574.html is the best source I could find on it.
Then you could study about how Facebook is made and their opensource technologies (like React that I cited before).  Also, there's Diaspora and this:  http://church.io/  to you read and get ideas
it needs to be able to run in the cloud (e.g. amazon) or be decentral  the main problem is adoption of course. i recently found out that almost all my collegues are still on whatapp for example.
Let's do this newLains! New programmers get together and let's dominate this course together!  We'll feel more comfortable and driven if we, as beginner programmers who are scared and know nothing, join together and help each other out over here.   If you're a beginner programmer and want to join us, you can find the course on Coursera. Yes, the info you send to Coursera isn't very private, but some of us are willing to take that risk for the sake of learning.   Also, please don't bully us new programmers for deciding to use an inferior online course to further educate ourselves instead of alternatives such as textbooks   this is the simplest way to learn something if we don't already know anything.  Without further ado..    print 'We want.. a shrubbery!'  
Not him. These are all possible using only the Python standard library. I also think they're all as fun to use as they are to write.  Password cracker for zip files. (Just guess a bunch of dictionary words.) Program that opens up a random file in some directory. (Porn Roulette) Program for hiding data inside a media file. (Pick one format and learn it.) Program for detecting and extracting hidden data in a media file. Program for scraping images from a website, like an imageboard or imgur. (Put a small delay between downloads so the site doesn't block you.)
https://docs.python.org/2/library/random.html#random.choice    
I'm reinventing the wheel like I always do   Thanks, anon.
and then you go and try to use a language that doesn't have a similar function and you get pissed off.
Haskell is quite popular among the lains, so tell me, why do you personally like/love Haskell? Biased and opinionated answers allowed.
Your loss.     4872  What about F#?  4858
try scheme then. Read SICP and you're god tier now
It's formalisms are just so formal.
Just finished LYAH and am currently following the Scheme in 48 hours tutorial. Haskell is interesting as it's different from any language I have used before and is the second language I'm learning properly (C was first).  I find it easier to read source code as it's clear what it's supposed to do and write good programs (it's hard to write a prorgam which doesn't work as GHC rejects anything wrong).
I'm right behind you. I only have a few chapters left of LYAH and I have the tab for the Scheme in 48 Hours tutorial open. I've gotten sidetracked with cabal though.
Is anyone else extremely turned on by well done UML?  I just came to pic related.  This is the third time this week. usually class diagrams, occasionally sequence diagrams.  Should I seek help?    id post this on /r/ but they prob dont understand the inherent sex appeal to UML. 
This site has some good looking UML:  http://www.uml-diagrams.org/ 
What programs do you guys like? I appreciate the customization and straightforwardness of Dia, but my work never looks very slick on it. I understand you can apply styling, so maybe I just need to play around with it more.
I use Dia and I think it looks very nice if you export it as SVG.  I was thinking about learning PlantUML:  http://plantuml.com/  but it doesn't look that good.
UML is nothing but an excuse to make bloated and uselessly complicated designs just so you get to use all those fancy symbols you learned in Intro to Architectural Design. Prove me wrong.
UML is just a modelling tool, you can use it to make clean designs.  People tend to make more complicated ones because clients keep changing their specifications and easily changeable designs are more complex.
How does one get a job as programmer? Do you walk into a *place* and say \"hey, I make software\" and you're hired?
Make a portfolio on github.
Find a position, send in resume, get interview, wait a day or two, send follow up email thanking them for the interview and reminding them how great the interview was, wait, get job. Repeat until job.
This, unless you have no degree and live in a third-world soykafhole, in which case contacts, personal references and working your ass off might get you a programming job.
Who online learning here? My course just started
There's already /edu/ and /freedu/ there.
Aww
Link please.  Also: where to get good pdf's/ebooks from?  It's pretty much the only thing I pirate since quite some time and I still have no reliable source.
/lit/331 
Ah right! Thanks.
Welcome to the Lisp General.  Ask any and all Lisp questions here.  Since /g/ currently has the 100th general, I thought I'd see how one of these would fare here.  Here's a link to the general's pastebin that contains many links to various books, documentation, websites, and other interesting information:   http://pastebin.com/u/g-lisp-general     To foster discussion:  Which dialect do you prefer? Do you use Emacs or a different lisp-based editor? What was your first experience with lisp? What have you made in lisp? What is your favorite Lisp program? What do you like about Lisp? How do you think Lisp is (one of) the superior programming language(s)? How long have you been programming in Lisp? What are your favorite Lisp resources? Please share, preferably links! Is Lisp your main programming language or not? Regardless, what do you primarily use it for? What would you like to see in the Lisp general? What was your favorite aspect of the Lisp machines? Do you think we'll ever get something similar to the LispMs again? What is your preferred method of documenting your code? In the dialects that allow it, do you make many reader macros or not? Do you use more than one dialect? What are they and which do you prefer?  Vote in our poll, if relevant:   http://strawpoll.me/2430767 
I've been dreaming up a GUI application framework written in C, but scripted using Scheme. The actual interface would be written in S-expressions almost like a markup.
Check out the CLIM applications (e.g. CLIMACS), it's a bit like that, but pure CL objects.
maybe guile-gtk then? though you'd still have to make some arrangements to get what you want
Racket does GUIs pretty good.
How would you implement the framework itself (in C)?
What's the best project for learning objects, algos, and recursion?
Wow, what the hell. I had no problem at all understanding recursion but I just got to the lambda chapter in The Little Schemer and it's blowing my mind. This soykaf is black magic.
how about backtracking using exclusevely OO?
lambda in python3 is amazing, so are delegates and lambdas in C#  anonymous code excecution == powerful but easy to misuse tool
The Y combinator? It's absolutely beautiful.
More on algorithms?
For discussing the state of the art of representation learning, deep learning, neural networks, machine learning, and all related problems.  Spawned from a discussion in IRC.  To get started, a good tutorial for those new to the world of deep learning / representation learning.  Baby's first Deep Learning tutorial:  http://deeplearning.net/tutorial/dA.html   Good literature review by Yoshua Bengio himself:  http://arxiv.org/abs/1206.5538 
is there any point in using deep learning on non-image/audio data?
Neural nets do a good job of generalizing to many different modalities. Maybe surprisingly, given the nature of the convolution  operation, there is a lot of research using CNNs to do Natural Language Processing.
While looking around for parsers, I found something that could differentiate topics, but I'm not sure if that was before or after I started archiving tabs..  Regardless, could there be a use for an embedded net?
all data can be represented in a visual or audio way. But I see you are thinking as a human, and with your senses, so yes you could use taste data, or smell data too.
What do you mean by an \"embedded net\"     4784  Right, anything that can be represented as a vector is fair game.
Ideas?
bumped from /random/ did anybody ever implement a solution for this? I know Tor nodes are derezzed but is there a hash library in use?
Haar transform. Keep the 10% strongest coefficients. Write down just their sign.  This ends up being a highly resilient fingerprint.
did anybody ever implement a solution for this?  Yes, multiple. There's an answer up this thread.
CP laws are thoughtcrime laws.
I think you should read the thread
What books should every programmer read?
Yeah, but why start over when you can refactor?
http://uubmub.com/books/linux/linux-system-programming.v2.pdf 
Masters of DOOM.  Because it gives you that thrill of being a programmer solving amazing problems and having fun.  also id software was awesome
Are there any outstanding books on Smalltalk?
You could try Squeak by Example.
/λ/et's talk about Machine Intelligence.  What is it? What can it do? Where does it come from? Who is producing it, consuming it? Why don't you have an w-ai-fu yet?  And perhaps most importantly; How would you build it?
Today it might be about recognizing specific patterns, but with new hardware it will evolve.  Drugs are bad, m'kay?
Note, the \"limited\" academic point of view that you're describing is the only reason why the very concept of Artificial Intelligence even exists.
I think you mean better software, not hardware. And there's already AI that does things other than detect very specific, rigidly defined parretns.
Isn't there this saying that when someone discovers a new AI technique it isn't \"real AI\" anymore. Because it's a technique?
parretns  Meant to type \"patterns\".     4795  Sure, people have said that, usually in response to projects that start with the premise of \"Well if we can make an program that can solve basic problem X then it must be intelligent!\"
do we need a C replacement?  what is D like?    have a wallpaper 
How is D or Rust a huge language? If you're referring to the standard library, Go has much bigger one than D, Rust or even C++.
Am I misreading this, or are you saying C is the easiest language to learn first?
Huge as in just core language, the massive feature count and number of different ways to do a thing.  Or you could see it as just the language specification size.
I think a C replacement with manual memory management is pretty pointless.  that's where almost all of the problems occur and not fixing that in a supposed successor is a wasted effort
I'm going to go on the record as saying no, we don't need a C replacement.  C is not the language for everything, but it is one of the best abstractions for an actual machine.  That's not entirely true for a multi-core machine, but I'm still not sure there's a better one.  That's exactly why C is so good at what it is good at.  It's also a simple, orthogonal language which makes it clean to write, if not easy to read.  What we really need is fewer  B-grade python-is-god programmers trying to fix languages that accurately express hardware architectures because something about not knowing how to manage memory.   That's not to say C is best for everything.  It's CERTAINLY not.  But asking if we need to replace C, without any clarification, is either flamebait or just a very short unclear post.
Let's start a bad habits in programming thread! I'll go first:    Absolutely perfectionist, and not in a good way! i've deleted thousands of lines of code just because i didn't like the final result and decided to start over. I once rewrote a whole website just because a couple pixels were off and i couldn't figure out the problem. ctrl+a+del     Would rather write the whole code on my own than to use a framework. Whats ironic about this that i actually write frameworks and share them on github     I get bored easily and start working on a new project every week     It's almost impossible to get me started, but when i do start i could spend 6 hours typing on my keyboard  
I'm super productive for implementing the features I need in my personal projects, and I am very good at documenting what is missing/what bugs I encounter and theorize. The bad habit is that as soon as the tool is useful to me, I stop development completely. I assume this is a really bad habit most people share.
the letters tend to be temporary values, I use a lot of anonymous methods, so I don't think of them as something important, they just represent a place where a value needs to be stored temporarily. That said, I realise that they make my code harder to read than is necessary.    For instance, loop indexes are called \"i\ \"j\", and \"k\"; not \"indexForArrayX\", \"indexForArrayY\", and \"indexForArrayZ\".   Another bad habit then is using the default index names, like in C# \"i\" for For loops and \"item\" for Foreach loops?",
No, no, I was saying that \"i\ \"j\", and \"k\" are fine, because that's an established convention. If someone sees a use of \"i\", they know it refers to the outermost loop.",
I can't read code, its not my fault though.     2508    try to make simple game engine    end up trying to program the universe 
Games where you code to do shit   https://alexnisnevich.github.io/untrusted/ 
Cool game, thanks.
This thread's probably dead, but  http://vindinium.org/ 
I think these are neat, bump
\"Robocode is a programming game, where the goal is to develop a robot battle tank to battle against other tanks in Java or .NET\"   http://robocode.sourceforge.net/   It's breddy gud, a bunch of guys all build a robot and see whose is best. Not much re-playability though.
It may be in ruby, but this game is kind of fun where you code the knight to fight its way through each stage:  https://www.bloc.io/ruby-warrior 
Would anyone be interested in making a minecraft-like wireframe imageboard space, likely in WebGL?  The premise would be that administrator architects could work on building a wireframe city, walls could be graffiti'd with text content for discussion and it could also host a general chat. Are any epxerienced programmers interested?
More network visualization:  http://corte.si/posts/privacy/neighbourhoods-of-trust/index.html 
Another thing that might look nice is a variant of cel shading that uses different kinds of dithering to quantize the image. Random dithering could be less scrambled looking when animated while still having a glitchy look to it, and combining the results of several dithering types could make a nice combination of patterns.
As far as UI goes www.reddit.com/r/fui has some great content.
in a thread literally about webvr, there is only 1 link and a single youtube video regarding it      3320     4429 
i feel obligated to bump this thread
What features would make sense in the next revision of the C standard?
Isn't C fine as it is? It already fills a needed niche, there's no need to make it something it's not.
Never settle 
Exactly why I'm asking what would *make sense*. Certainly nothing like objects or whatever, but the question is, are there any gaps in C in terms of the niches it already fills?
C89 is the standard, it doesn't need another revision.
Hello my dear lainons.  I know that many of you are great programmers, so I must ask you something. I'm going for my second year in the college. I`m currently doing Computer Engineering and my classes are like 30% math and physics, 40% computer science and 30% electrical engineering. I`m pretty good in the electrical engineering and physics classes. But I'm absolutely garbage in programming things and in pure math. Most of my peers program many nice things but I seem incapable to do so.  Was any of you guys like me? How did you became good in abstract things and surpassed your difficulties?
Oh, sorry. There are two points to be honest. The first is recursion. I failed every test and exercise about recursion given to me. The one about Towers of Hanoi is unfathomable to me. I read it dozens of times and still can't understand what happens.  The second one is about reading other people code. I don't know why but is very difficult to me to keep track of what the program is supposed to do if it was not me the creator of such program.
Recursion is simple.  Let's say you have a function count-to-ten than takes one number as an argument. The first thing it does is check if the number is larger than ten, if so, it exits. Otherwise it prints out the argument, then calls itself with the number plus one. So then it prints out every number between n and ten, inclusive. Get it?  As for reading other people's code it's just a matter of understanding the techniques involved. When you read the code, stop and think \"what, exactly, do I not understand here?\".  If nothing else it's time to print out the code and annotate it until you understand, it's a good technique.
Thank you. I will try what you suggested.
Try doing recursive algorithms by hand on paper.  Reading other people's code is just practice. Stop skimming over code examples in textbooks.
Recursion is just when a function calls itself. It's no different to calling any other function.  What about it are you having difficulty with?
I wrote up a little guide explaining the y-combinator. I'm looking for critics. Are there any parts I could be clearer on? Is it useful at all?   https://www.refheap.com/96744 
It's pretty good I think.
this is the clearest derivation i've seen I really like the way you did it
Thanks. How have you seen it explained before? Was it just math instead of code? Did the explanation work backwards?
pretty good lainon 9/10
I want to create a custom lockscreen for my android device.  How do I start?  Do you have to use java, or could I use golang or python, or even lua?  I have literally no knowledge of android or android programming, so just shoot me some links/advice/whatever.  Thanks a bunch!
Sup Kurt?
Leverage the type system to the fullest and use total functions everywhere. There, your program is now safe.
There's more to a program being right than merely not crashing.
I recently started digging into Coq and how to leverage it for development (e.g., Bedrock, Ynot, CompCert, etc.). Does anyone have any experience with this and could point to some resources?
Found or written any soykafty code? Post it here. Hopefully we can learn from past mistakes.
dude you are a huge dick
trips confirm . I actually cant tell if this is bad code or not, can another lainon explain?
I was tired one night and wrote this. It's part of a function that processes user input.    (do* ((response (progn (format t question)                        (read-line t))                 (progn (format t reprimand)                        (format t question)                        (read-line t)))       (answer #1=(or (and (listp validity)                           (or (car (member response validity :test #'string-equal))                               t))                      (and (stringp validity)                           (or (and (string-equal response validity) validity)                               t))                      response)               #1#))      ((stringp answer) answer))    I had apparently forgotten what typecase was. It looks so much better fixed.    (do* ((response (progn (format output-stream question)                        (read-line input-stream))                 (progn (format output-stream \"~?~?\" reprimand () question ())                        (read-line input-stream)))       (answer #1=(typecase validity                            (list     (car (member response validity :test #'string-equal)))                            (string   (and (string-equal response validity) validity))                            (function (funcall validity response))                            (t        response))               #1#))      ((stringp answer) answer))    I will never make that mistake again, no matter how tired I am. Remember Lainons, if your Lisp is ugly, you're probably doing something wrong or you need to write a macro.
(tagbody   a \"Gotta stop my code from bleeding to the right.\" (go b)   b \"Gotte get rid of all these let/let* blocks. What is this? C?\" (go a))   
Which of you lainons own a startup or thinking about starting one? Must be software or web-dev related of course
Once you finish it, you will be sure to do a Q A here, right?
Honestly, I don't really see the appeal in startups. From what I heard, you are supposed to work 16 hours a day for little or no pay in one of the team member's basement until you can convince a venture capitalist that you will make him even richer.  Honestly it feels like a giant conspiracy by the big corporations to outsource R D so they don't have to pay for the failing ones.
Certainly. I couldn't ever make it happen or even get the idea without /g/entlemen.      3812  Startups with promise are \"headhunted\" by bigger companies like professionals with value. Typically they want the know-how if creating competing product is too demanding, disruptive or expensive. Investors should be convinced before even going on the basement stage. Some choose to do it all without external funding. Like Microsoft and Baidu.
I'm testing my own service with a real company these weeks. My service is in the general corporate communications sector. I've been through two incubator programs and am currently lining up two more companies to test this with.  My stack is mostly node-js + angular - I know, but please don't smack me.
Do you know how to program? What languages? What math courses have you taken? Are you experienced with GPU programming?
Functional reactive programming?  Has anyone investigated and used this in practical application like complex gui or game?
The biggest problem with programming games in a functional language is the giant state object I have to take apart and build up. Do lenses help with that?
Idk, probably something in the lines of guitar hero like gameplay would be the most natural simple case that comes into mind.
I also want to know the answer to this question.  The only thing preventing me from implementing a game in Haskell is this, basically.
lenses are a joke.  use IORefs if you want lots of mutable variables.
Dealing with nested data structures is exactly what lenses are for.
Lately I've been working on testing concurrent Haskell programs. Concurrency testing is interesting because the scheduler possibly imposes some nondeterminism, which is generally out of reach of the programmer, and so just writing regular test cases doesn't work. Concurrency testing works by overriding the scheduler and forcing particular schedules on code, to get repeatability.  Naturally, because there are a lot of schedules for anything nontrivial, you can't really explore them all, so you try to prioritise schedules likely to be interesting, and come up with some ordering over the space of all schedules, and then gradually explore the space.  The way I've done this in Haskell is with a typeclass abstracting the concurrency primitives of interest (fork + some mvar stuff), with an implementation using IO so your code works as normal in production, but with another implementation which forces everything onto a single thread and uses a user-supplied scheduler, for testing.  So I now have a little library for writing concurrent tests (eg, \"this never deadlocks\ or \"the result is always this\", or \"this predicate always holds over the result\"), which can be used as a debugging tool (in, say, ghci), or as a tool for producing pretty test output, as in pic reated.",
Very cool. Are you going to publish?
\"Don't do it\" isn't really a solution. Besides, coroutines don't support pre-emption, so what happens if something goes into an infinite loop before it gets to a point where it can be interrupted? Also, pre-emption isn't the only source of problems, sometimes a non-pre-emptive but unlikely schedule might expose a bug. Concurrency without massive restrictions always has the potential for nondeterminism.     4500  Got a few things to work on (in particular, trace simplification) first, but my supervisor has suggested aiming for a paper in this year's Haskell Symposium.
Is this a kind of \"probability testing\" like QuickCheck or do you formally prove that a certain program/function won't run into a certain condition?
It does systematically explore schedules, so there's no repeat work done. So you could let it run over all schedules to guarantee behaviour. However that could take a long time, so by default it only considers schedules with N or fewer pre-emptions. Empirical studies have found that N=2 gives good results (and that's what I've found when implementing test cases).
I've been working on shrinking yesterday afternoon and today, and now I have something rather nice, see attached before and after images.  It does take a little time. The first two examples are nigh-instant, but the third takes about 20 seconds, as it's got three threads and running the computation with lots of derivative schedules to try and work out where exactly the bug is. I could probably do better by doing a little static analysis of the dependency between reads and writes, but at the moment I don't gather that data.
I am currently working on simple keylogg in C here, it runs pretty smoothly though I'd like to know if there is an option for uni access installing workaround, based anon, pls help.  my code is smthng like this:   http://pheast.ru/!/R/R288.html   key is gnu4u
hey /λ/ , i was thinking about how to teach myself most of what an average programmer should know . yeah i do attend uni but its not like a pay attention , and its not like they teach anything anyway. i have tried the gentoomen library but its just an information dump and there is no structure so i don't know where to start and where to go after that   mostly i'm just looking for some sort of structure or must-know course guideline to follow , because i know some programming but my knowledge is sparse and fragmented
If people do not believe that mathematics is simple, it is only because they do not realize how complicated life is.  — von Neumann
Computer graphics also uses topology - which is math. Networking is mostly basic algebra - which is math. *nix system administration is best done understanding chaos theory - which is math. Windows system administration is quantum mechanics in and of itself - only understandable through math with meth.
I remember reading this haha
I only attend it because I dont pay for it and also for the Network, but you still are right. I spend like 2 hours just to get there, and most of the things they teach, I already know. I could just stay home studying and not waking up 5:00am almost everyday and go to uni only todo the tests, but it is not allowed. If I skip over 25% of the classes I automatically lose my scholarship ;-;
Nice set or courses right there. I so CS and it is all about dev(even web classes), with a few real CS classes.
So, I was looking for information on concurrency, when I came across this fascinating piece of (tragically defective) engineering, which I thought I'd share:  From Wikipedia: \"The Therac-25 was a radiation therapy machine produced by Atomic Energy of Canada Limited (AECL) after the Therac-6 and Therac-20 units (the earlier units had been produced in partnership with CGR of France).  \"It was involved in at least six accidents between 1985 and 1987, in which patients were given massive overdoses of radiation. Because of concurrent programming errors, it sometimes gave its patients radiation doses that were thousands of times greater than normal, resulting in death or serious injury.\"  A more detailed investigation:   http://courses.cs.vt.edu/professionalism/Therac_25/Therac_1.html   The problems were not just related to software design, but also due to lack of documentation and almost zero due diligence on the part of the machines manufacturer, who overstated the safety of the machine to an overwhelming degree.  Which I suppose makes this a thread on professionalism in software development, and what not to do when writing safety-critical systems.
Eiffel, Ada, and Rust all seem interesting too. Ada seems to have died out, though, as NASA/JPL use C++.   It's a little odd that a focus of Rust is safety, and yet the language doesn't have a standard, only a reference implementation. Until that's remedied, that just makes it totally unsuitable for safety-critical stuff, as you can't formally analyse what's going on.  Ada is nice, though. A bit verbose, but the language itself is very well put together for safety, and then you also have toolchains like SPARK on top of it for even greater guarantees.
Ada seems to have died out, though  Its actually on the rise. It did fail as a mainstream general-purpose language, this is what it was conceived to be at first. However in its niche as safety-critical language its quite alive.     4431    Ada is nice, though. A bit verbose,  I think this is what makes it great. Sure its a bit of a drawback when typing code (then again if your words per minutes have a significant influence on the code you output you have other worries), however even people who have never learned Ada can infer what the code is supposed to do when reading it.  And since Code is written once but read hundreds of times this is a hue plus for Ada.
The Swedish JAS Gripen 39's software is written in Ada.
I read an article about programming for NASA, how they never worked more than 8 hours a day, strictly 9-5 job.  apparently lots was done in assembly, not for the speed, but so that they could guarentee no bugs, who knows what a compiler is doing.
NASA pretty much uses a very strict subset of C++, at least on the Mars rovers:  https://www.youtube.com/watch?v=3SdSKZFoUa8   There's also that one article everyone always links to about Lisp being formerly used at JPL:  http://www.flownet.com/gat/jpl-lisp.html   And for coolness, an NSA subcontractor developed a Haskell DSL (targeting safe systems programming) that compiles down into C:  http://smaccmpilot.org/ 
sup lambdas  this is probably not a programming question, but i think it still fits on this board  well it has come to my attention that firefoxos doesn't actually run on general purpose computers, but rather mostly just phones, (it uses the aosp linux kernel)  as you probably already know chromeos is based off of chromiumos, and it uses the mainline linux kernel (mostly)  how feasible is porting firefoxos to a chromebook?  i've read that porting firefoxos to a raspberry pi involved stripping out aosp and replacing it with a vanilla linux kernel, and some opengl related patches  ffos is modular so you have gonk(kernel)   gecko (basically userspace)   gaia (ui)  so am i mistaken in thinking getting firefoxos (gecko and gaia) running on top of chromiumos' kernel is possible?  the extent of my knowledge is based off of linux from scratch, i don't really know the extent of the work involved in a project i'm proposing, so tell me if i'm dreaming.
I just want to make a Firefoxos based alternative to desktop chromeos, simply because I think that would be cool  I know a few people that run Chromebooks with stock chromeos and they love it, I'm just disappointed to know firefoxos doesn't actually target desktop users
In that case head over to XDA-Developers, they're probably more knowledgeable about that kind of stuff.
FirefoxOS is targeted to people with no resources that need something very cheap. So the simplest and the lower resources you can get, the better.  Looking at the comments in the Marketplace you see how many come from third world countries (specially Latin America). I really hope they get to this market, as Mozilla is one of the few companies I have some faith on 
how is forcing these people to stick within a browser not oppression? it takes away their agency and ability to control properly what their computer is doing
You could probably say the same about any smartphone OS, without a computer on the side, it is not possible/practical to change the system. A phone is a consumption product, not a production one.  But I don't know if you used it, but being web-based does not mean \"you only have firefox\". It feels exactly the same as any smartphone I ever used.  But if you want to change whatever the system does, the stuff is open source. Your limitation is just to have a HTML+CSS+Javascript interface 
Any /lam/bs working on p2p projects?    topic ideas:  data portability (people can own their data and move it from one app to the next, no company data silos) mesh nets p2p cryptocurrency stuff distributed social networks messaging stuff moar?    essentials:   https://github.com/redecentralize/alternative-internet 
Ive been thinking about doing some p2p discussion board. It would be a mix of Usenet, Torrents, chans and TOR routing (optional).  I got the idea while reading a book on XMPP which seems to be an extremely powerful protocol that also supports encryption.  Its only a very rough concept but I imagine it would work along these lines: - All clients are Servers, there are servers but from the viewpoint of the application those are just nodes that are online all the time.  - Conversations are thread-oriented same as on *chans or usenet.  - All (text) posts are stored on every node (if you read a discussion, the posts are downloaded and stored on your computer), it should probably be possible to have the user chose if he wants to store the pictures (or other data) too or only the text.   - related to above: various means of deduplications for the files accompanying the posts such as hash values (if the post has an image thats already on your disk the program wont download it again but instead embed that file. As a bonus it would also be possible to blacklist known CP files without getting into legal trouble)  - For the p2p aspect: to read or discover new threads the user could query any of the peers, be they PCs or Servers. Once he has the adress of one node from that he can receive the adresses of more nodes to enable faster downloads of files (like the BitTorrent protocol). This should make it possible to include files of almost arbitrary size in the threads. (see below for the encryption: in this case it should definitely be symmetric. Or at least hybrid: asymmetric encrypt the symmetric key before transferring it)   - We might write a dedicated program for that, but honestly I think that using Firefox plugins or just plain old websites + JavaScript might be better for the acceptance and more pragmatic as it would mostly be web-based anyway. (no need to reimplement the HTML-parser wheel)  (1/2)
(2/2)   - For the security: It would be possible to encrypt the whole thread (it would be one file that can be downloaded by everyone, just not decrypted unless you have the key) or single posts (im honestly not sure how to implement that one)  - Encryption scheme should definitely include PKI aspects, that way users could also sign their posts (maintaining anonymity while still ensuring authenticity).  - With PKI it would also be possible to create invitation-only threads: The OP would include a sort of invitation file that is unencrypted and contains the public keys/certificates of the invited ones, thus only they could decrypt the file. (Problem here: the file would have to be copied as many times as they are people invited as it have to be encrypted with each of the public keys, this screams \"ugly hack\")  - Maybe include TOR-like routing: nodes would not send data directly to each other but along several other nodes along the path so that it is more difficult to find out from whom the data really came.    What do you guys think?
AFAIK cjdns won't work on normal mobile devices like an iphone or android  Why not? They don't have to be servers, just clients to the network.
Also check out lainet thread.
Non-IP Addressing  DHTs?     3929     Anon Messaging based on Subject Keys  Have y'all heard of Ethereum's Whisper?     3954     3957  DEV's libp2p? For multiplexed p2p net layer and peer optimisation?     4432     Usenet, Torrent, Chan, TOR  How about IPFS (of IPFS.io) in place of bittorrent? The main issue is that it makes data immutable, but it should be more decentralised, and harder to starve torrents. :v
Hello, my fellow Lains.  I'm looking for some resources (books, textbooks, lecture notes, webpages, blogs are fine too) that are concerned with the construction and analysis of computer viruses, worms, exploits, rootkits, trojans and malware in general.  Preferably in platform- and language-agnostic manner, that is, some examples of code are fine, but I'm more interested in the formal, abstract side of this topic.  (I would usually post this on /g/, but Lain seems friendlier, and there seem to be more people who are knowledgeable about topics like this and are willing to share. Also, I wouldn't probably get much else than  OP wants hack google kek, gtfo script kiddie, etc.)
VXHeaven
I thought vxheaven got seized?
Yup, it's been back online for ages.
good, I have the archive, but I don't know where it is. But I guess it doesn't matter now.
avaxhome.  They have in their \"big book collection\" category a \"malware and virus collection\" which IIRC is quiet  big.  Basically lots of ebooks split on 5 .rar archives.
Hi /λ/,  I seem to crash and burn on phone screens a lot, especially when the screener goes into technical questions. (Get me in the door to a 'hands on, show us what you can do' and I am fine, get an offer near every time.)  I feel like the person doing them mistakes my asking clarifying questions for me not being competent, or having an issue with my communication ability. Or worse, like I experienced with Amazon recently, people looking for me to write optimized code on the spot in a txt program from a shared screen over the internet. (For the life of my, I cannot recall anything unless I am at my own dev set up, or a shell. Here I was on a tablet and smartphone, because I was told they'd wanna see what I knew about AWS arch.)  Does this mean I have a lack the talents needed to be a programmer in most companies? Or that I lack the talents some expect programmers to have? Any advice for how I can improve? I try practice interviews when I can. Is there something more specific I can do?  Also, why does no recruiter if they are going to take the time to phone screen me, check my portfolio first? Is it just not worth up keeping?
I think it's because you are aiming for popular companies like amazon, google, etc. Why not just go for local programming jobs? Some of them got a nice team culture.
Thanks, I was thinking it might be that to. Google, as an interview experience was very good once I was past the phone screens. But yeah, the majority of big name tech firms where I am do seem like they are more interested in saying no, or making you feel like soykaf so you'll be grateful they gave a 'pleb' like you a job.  I keep looking and applying locally. I think my issue there though is I don't know anyone where I am now. Which seems to be the best way to go about getting into a smaller more narrowly focused company.
Maybe it's just your nerves?
i would do a few things:  before your phone interview; take a good 10/15 minutes to do deep breathing exercises; let your voice relax into its normal register (im imagining that you're getting nervous and sounding a bit high pitched, scared).   get nice and relaxed before it starts.  also, get a friend of yours to sit in on your next call and get them to give you brutally honest feedback on your performance; maybe you're doing something really annoying/bad and you dont even realise it. they should tell you this.  also, it sounds like you've done a few interviews like this already, so you should have an idea of the kinds of questions they're going to ask you; so before you do another interview; sit down with a note pad and write out the questions; and then spend as much time as you need to figure out your perfect, perfect answers; and then rehearse them.  pretend you are a politician about to go in front of the media; be relaxed calm and in control.  also, if you're asking too many clarifying questions; just go ahead with assumptions; sometimes you dont look good if you ask too much; its art; just plow ahead a bit more.
Its perfectly normal to be nervous and even hate technical interviews.  Most coders, even very good ones hat that too.  This does not mean at all that you are not cut out to be a coder, on the contrary it simply means that you are not cut out to be an interviewee. Considering that your job will most likely be coding and not getting interviewed if you are hired, that actually great.  As other said: do a few dry runs, ask a friend to ask you mean questions and try to answer them inside a small time window. Basically stuff that will harden you up for the interview.  Any company worth its salt will also be aware that great at interview != great at work and vice versa.  Dont be too gung-ho about Google and Amazon either, these people are not the best by far. I heard from a friend of mine who studied mathematics quite a few horror stories about how the interviewers from Google often have their Head up their asses. (Horrible indian dialect, bad phone connection, no clue about IT-basics, demand the interviewee knows version-specific trivia etc )
Anarchic because: No Gods, No Masters. Democracy because: Individual voting defines society.  N.b. Originaly called this idea Organized Anarchy  but have since more accuratly relabled it.  ITT I ask those who are interested and able, to help (start) build (program) a new and just system with which to define and steer society.  New technology brings new opportunities. A system never before considered!   We have had many systems of control and order, each “progression” becoming larger and more complex. We have had many systems of voting and power division.   Until recently there was no realistic way for “the people” to control or dictate the workings of government, only to vote for someone else to control and govern.  This is ultimately not allowing “the people” to have a near proportional say in the workings of humanity. We just have a 2 way switch between parties that ultimately are engaged in keeping the interests of  PRIVET businesses and wealth above that of a truly equal and just society. This seems to hold true in many shapes and guises the world over, all be it with variations on voting and ruling systems, but ultimately there is deliberate distancing of the people, for the benefit of the few.   So come the revolution, as we clean the blood off the walls  What then?
Direct democracy doesn't work unless people are smart enough to understand the issues provided and patriotic enough to lobby for them.
unless people are smart enough to understand the issues provided   Wiki sir Wiki  Access to proper information for the masses is only about 10yrs old. There is plenty of room for this. Belief in a proletariat ruling class some how having a God given ability to understand things us mortals could not is rubbish, a propaganda weaved over the ages. Give people access and freedom and the sum of the parts will far far outweigh the de-creped and skewed system we currently have.  Think its very judgemental of you to say that about people - you know if you took a human of 10,000yrs ago and brought 'em up in today’s society 'ey would blend in perfectly, could be a high flyer  access and privilege are the key, not so much genetics or parents job complexity - plenty of \"simple folk\" became and are grate inventors and scientists and musicians and pilots and engineers and administrators and managers and all the rest – politics for the few is only believed by the few.  N.b. comments and crit. that is useful, all welcome - a straight it won't work is rather lame - just leave the topic if you have no belief in it and nothing to add.
in a proletariat ruling class some how  in a proletariat and a ruling class some how
patriotic enough to lobby   implying the poor and rich can lobby alike.  implying it's about a country and not a humanity.  implying lack of involvement in politics is not because of any ability to affect things in any meaningful and direct way.
Moved to     /r/6474 .
Sup /lam/bs, Ludum Dare 31 is happening this weekend!   http://ludumdare.com/compo/   Who's taking part? I'll be entering the Jam with a few friends, done a couple before (one with a time travelling platformer, and another with a roguelike). Voting on the theme is STILL OPEN, so get on that!
Rate of zombie spawning gradually increases, too. Which results in things starting to phase through walls eventually as the collision detection starts to fall apart  But it does at least increase the threat!
that's typical zombie behaviour.
It's a feature!
Here it is in its final glory. Better map, hotzones with activities, and better AI.  Zombie and human pathfinding is better now, with zombies tending to flock; there are also windows and barricades (which don't obstruct line of sight or bullets) to make it more interesting. Humans can tire, which makes their accuracy and ability to dodge bullets suffer massively, at which point they need to be sent to the rest zone to recover. Reinforcements (both human and tank) can be called in my manning the appropriate hotzones for long enough, but as the zombie threat continually increases, and the windows and internal doors can't be repaired, defeat is inevitable.  Although the submission is done, pathfinding could be much better, and I might play around with that tomorrow.
Ah, 87 days until LD32, I guess it's time to start preparing!
You hate it, I know. Probably has been asked often. Sure. Please have mercy, Gods of code.  I want to make a video game. Yes, I know. Hmhm. It won#t have any effects, no 3D graphics, in fact I want it to be abstract, mostly numbers. A resource allocation game.  Pic related is Subcommander. It's quite an interesting game, already beyond the scope of what I had in mind. I envision a game where you are a fabricator-AI controlling a nanofactory. You allocate resources on different production lines, influencing the ratio and designs of products produced. From time to time text adventure like events are triggered and your decisions change certain parameters.  I studied some C++ due to university and dabbled a bit with C and Python. I doubt I'm advanced enough to make this game happen, but I don't even know where to start.  Wat do?
cool, feel free to share results or ask question or something because i admit i only messed with python briefly, and also there isn't much going on on /lam/ so anything is welcome imho
How is tradewars licensed? As far as I can tell, just looking at Wikipedia, versions of the same game were independently developed by several people. As far as I'm concerned, going by that information, it'd be legally acceptable even to monetize your own version of that.
ch.org/agdg/ has some beginner resources, if you're interested
Link doesn't work    4391  Hmmm curious    4388  Will do.
Try  https://8ch.net/agdg/ .  There's also this course:  http://programarcadegames.com/  which is basically a cs101 by game programming.
What you think about NoSQL? Hipster soykaf, a fad, or something that have its uses?   http://www.rethinkdb.com/  is one that looks good to me.
i'm in favour of questioning traditional OOP, but surely objects are often the best way to represent data?      4253  what? please elaborate.
OOP is two things; the first half is obvious and the second half is a mistake.  The obvious part of OOP is abstraction of data. Defining new data by surrounding existing data types with an interface. Every language that isn't a turing tar-pit supports this. When I say OOP is the problem, I mean Java/C#/Python/Ruby-esque OOP.  Imagine a graph represented by \"Node\" objects with pointers to neighbor nodes and a graph represented by a list of boxed objects and list of edges between those boxed objects. Which do you think is more idiomatic in conventional OOP and which do you think is easier to serialize?
well what do you suggest then? using SQL forever but throwing away OOP abstraction? how do you manage the complexities of   stuff without going crazy in your world?
pretty much came here to say this.
So it seems the most major problem is updating static schema in SQL, and dealing with polymorphic schema in NoSQL.
i want to play around with arduinos, any of you fancy showing me your setup so i can pinch ideas from it? currently being a pleb and using the IDE + notepad++, considering switching to emacs if the extensions are convenient enough
also can someone help me with a vim problem really quick:     i    0    0    0    ESC    i    1    1   result: 00110  wtf, what am i doing wrong
When you hit esc the cursor goes back one character. You should use a (append) instead.
One thing that sucks about both of them is that their keystrokes are exactly opposite sometimes, e.g. the M-Y for paste in emacs and Y for copy in vim. Really annoying when transitioning.  Thanks to this, I now associate the word \"yank\" with putting something down.
i to start at the cursor a to start after the cursor see    4315 
i use sublime with the Arduino app set to \"edit in external program\".  i switch back to it and do the shortcut buttons to compile and upload.  since arduino code is just C; then i set sublime to color .ino files as C code.   wordsgoodman.jpg
It's Lainchan, it's always an ethical issue.
tell me you are joking.
I never got arround using the apply functions. I was happy just looping arround! Guess i need to up my game.  Have you used languages other than R for data analysis? I just installed Anaconda to play arrond with. I find python so much easy to use than R  Do you plan on take more courses of the specialization?
Just seems like such a dumb decision on the part of the site that I don't see why someone trying to teach wouldn't use a different one.
Or I'm being extra dumb and only need to enable javascript in the first place.
Anyone here read Total Functional Programming (Turner, 2004)?  I'd known the rough idea (separate data/codata and recursion/corecursion), but naively assumed that because it results in a non-Turing complete language that it wasn't really useful outside of the context of metalanguages for proof assistants. The paper makes a compelling argument, though, and I'm no longer convinced.  It boils down to a type system distinction between data (which is finite) and codata (which is potentially infinite), and a set of four rules.  1. All case analysis must be complete. 2. Type recursion must be covariant (see pic related).  Rules three and four only apply to data+recursion and codata+corecursion, respectively.  3. Each recursive function call must be on a syntactic subcomponent of its formal parameter.  This is essentially a restricted version of structural recursion, which is of course guaranteed to terminate when the parameter is finite.  4. Instead of descending on the argument, as in recursion, we ascend on the result.    codata Colist a = Conil | a    Colist a  f :: something -  Colist somethingelse f args = RHS(f args')    The leading operator of the context RHS must be a conconstructor, with a corecursive call to f as one of its arguments.  Or, to put it more simply, corecursion must be constructive.     So how does this prevent nontermination? Well, to give a simple example, we know of course that trying to fold an infinite list will never terminate. However, because recursion must be structural, we can't even construct an infinite list!  So you might think we can construct an infinite colist. Infinite structures is what codata is *for*, and we can:    ones :: Colist Nat ones = 1    ones    However, because corecursion must be constructive, we can't write a fold on colists! We could instead write this:    cofold :: (b -  a -  a) -  b -  Colist a -  Colist b cofold f z (x    xs) = let z' = f z x in z'    cofold f z' xs cofold f z Conil     = z    Conil    Which is kinda like an incremental fold. Importantly, it always produces a result.  Naturally, we can see some limitations with total functional programming, at least as proposed by Turner. We can't get the length of a Colist, as it might be infinite. However, maybe the subset of Turing completeness it offers is enough to do useful things. We can still deal with arbitrarily large structures, we're just required to be able to handle the infinite case.
Everything operating on data terminates, and everything operating on codata is constructive. So, there is no bottom.  Furthermore, the lack of bottom makes lazy and strict evaluation semantically equivalent.
How can one use total functional programming within the context of dependent typing?
I can't speak for the other dependently-typed languages, but Agda is total. Although I'm not sure if the extra power added by dependent typing means you need more (type-level) restrictions than the ones mentioned above.
Yeah, the Colist example can use thunks to generate an infinite stream. But the important thing is that the language enforces a way of consuming potentially infinite structures which is *productive* - that is, it works even if the structure is infinite. And for that, the data (which is finite) and codata (which may be infinite) type distinction is necessary.
sup /lam/bs  I want to write a webapp and have it usable as a 'native' phone application too  The things I've seen that allow this are apache cordova and ionic framework (which seems to be based off of cordova).  I can't figure out the differences between cordova and ionic, but I want the webapp side of things to have angularjs user interfaces and soykaf. So does that mean I should probably use the ionic framework?  webdev makes me feel retarded, so please bear with me, thanks.
native phone application  What does that even mean? You want to be able to use an application cross platforms? Then make it run in a browser with HTML5, CSS3 and JS. So you just need to choose a proper framework that handles the boiler plate and service. Since this is /λ/, I would recommend MFlow if you want the best or Node.JS if you want hipster cred. You want to actually run a program natively on the phone? Cross platform? You cannot, in any rational way.
You can use angularJS on any one of those platforms, I think. Just try them out and write a few simple test apps, see which one you like better.  But I highly suggest learning native mobile code because making web-based things is dirty and hard to deal with when you want to do something more advanced.  I've heard that Objective-C and Java are similar enough that you can write two apps for iOS and Android concurrently without much strain in switching between the two languages.
Use SmallTalk and SeaSide.
Haxe and Construct 2 seem to resemble what you're asking for.
Not for op but I found labmda native for compiling scheme apps on mobile and desktops today. Looks pretty dope.     3841    I've heard that Objective-C and Java are similar   dafuq?
To fellow established developers and programmers in their field, it would be nice of you to start a thread stating in it your expertise and answer people's questions. Make sure before that there is no other help thread with your same expertise, and in case there is just state in it that you are also available for help. We could also share related works in those threads or start projects. And if mods find those threads to be helpful and a new part our community they could pin the most useful ones in the home page hopefully! Let's make this our thing.    Suggested domains:   Frontend development (HTML5/CSS3/JS..) I'll take care of this one    PHP    RUBY    C++/C    JAVA    ANDROID SDK        *Please only start a thread if you're fully confident of your skills*
Lainchan is still young and not generating enough income. Once the donations and ads money start flowing, i bet they'll start archiving
You're missing the point. An anonymous image board is a bad place for asking questions because it makes it harder to find what's already repeated. Archives aren't even really \"in the spirit\" of an image board.
Please only start a thread if you're fully confident of your skills  I thought the only people who were fully confident in their skills were those ignorant enough to feel like they had nothing left to learn.
you never stop learning anon, but you reach a point of experience and knowledge where you feel you can help people a little as others helped you when you started
It's not possible to learn everything, but it is possible to learn a small subset of it, and be confident in that small knowledge.
There has been some interest in a new board for electronics and embedded development. As embedded development fits in /λ/, I've decided to let this be the programming and electronics board.  If there is enough interest in the electronics side of things a separate board will be made, as /λ/ will remain primarily about programming.
Anyone know how Swift handles really big reference counts? I'm asking because as far as I can tell it *only* uses reference counting - but then if your refcount exceeds the limit of the type containing it, your program just breaks.  And using bignums or 64 bit ints would be a massive space inefficiency for most objects.
It crashes and you can do nothing about it. Enjoy your proprietary language.
I'm asking because as far as I can tell it *only* uses reference counting  One day a student came to Moon and said: “I understand how to make a better garbage collector. We must keep a reference count of the pointers to each cons.” Moon patiently told the student the following story: “One day a student came to Moon and said: ‘I understand how to make a better garbage collector    http://catb.org/~esr/jargon/html/koans.html 
I've finally understood this. Soon I'll attain satori!
Not so fast. Pic related.
Cycles can be overcome with weak pointers, which Swift has. Having said that, I think that forcing the programmer to think about the failings of the memory management syetem in this way is not a good approach to take in general.
There was some interest in   996 about making a lisp. Who's up for this? Maybe we can get the ball rolling and start the first /λ/ project.  Thoughts:  - Do it in C, because everyone knows C.  - Don't need to use a parser generator because Lisp syntax is so simple (inb4  lisp has no syntax).  - I'd prefer it to be lazily-evaluated, because then `if` doesn't need to be a special form - but that makes side-effects more difficult to reason about.  - Could do garbage collection with a hybrid reference counting / generational collector.  We should start by figuring out what specific things we want to make it *our* Lisp.
That's the implementation, but what about the language itself?
Found nothing about that, but the whole license page seems very hostile to me. They even claim that their license is more free than the GPL.
Well, I sure hope nobody implements the language from scratch and GPLs it.
It wouldn't be against the licence.
That was what I was insinuating.
It used to be that C and C++ programmers had an incentive not to split their code base into too many files. For example, it would be stupid to have each function in its own source file. Translation units were fully independent and doing this would prevent certain compiler optimizations. Some people had scripts that would take all their source files and combine them into a single translation unit that would then be fed to the compiler; this was done so the compiler would have a wide view of the code and thus be able to better optimize it.  Enter link time optimization (LTO).   https://en.wikipedia.org/wiki/Interprocedural_optimization   http://gcc.gnu.org/wiki/LinkTimeOptimization   http://llvm.org/docs/LinkTimeOptimization.html   With LTO, the compiler's thoughts about the code is saved in each object file and thus the optimizer will have context when the time comes to optimize the whole program.  This gives developers free performance gains and by eliminating performance penalties allows them freedom when structuring their repository. It could also mean performance gains when linking against libraries statically.  However, it does increase build time.
that looks cumbersome at first But it's truly modular. Though I'd just wrap all functions in structure cause the more branches the more annoying
What do you mean by the \"the more branches the more annoying\"? Too many file system objects? I'm inclined to agree. It'd be nice to have some editor support for a \"catted\" view of multiple function files.  One function per file trades compilation time for linking time. Less code per translation unit versus more object files. Now, this approach is at the very least no different than others in terms of optimization.  I think it's nice approach for the build system I'm slowly hacking on. My idea is to run the build system as a daemon that watches your code base for changes and compiles your translation units when you save them, caching the object files. When you want to run or distribute, it just links everything.
Given that if you're using some data structure (or whatever) you probably want several functions which operate on it, rather than just one or two, is there really much advantage over structuring your code this way?
To me, it's more about correctness than anything. Also, what I wrote in    1893 .  I'm not the only crazy one, though. The authors of musl, a C standard library implementation, also structured their code this way.   http://git.musl-libc.org/cgit/musl/tree/src/math 
Also, it makes statically-linked programs smaller since linkage is based on object files and not on the actual symbols. One function per file results in smaller, more atomic translation units.
How can I find out if I'm the best programmer?
by not creating shit threads like this? sage has been used
You're not. Please try to make more constructive discussion from now in.
There is none. Also, off topic.
I've been learning Ruby lately and its the first language i ever learn that uses the command prompt! I'm extremely confused with everything and don't know if it's worth learning
Aren't some more focused on being easy and useful out of the box? Ubuntu, Mint, Fedora, Debian 
The only difference is that you have to go get flash, media codecs, etc. yourself in \"non-easy\" distros. As    1787  points out, the difference really only comes down to package management. In a distro like Fedora or Debian you have to enable non-free repos yourself to get the non-free stuff windows-babys need to keep their withdrawal symptoms in check. While Ubuntu and Mint gives you that shit out of the box. Other than that its all just linux.
I know that i should have asked myself this way before. But do you think that a frontend developer/ backend developer is a common thing or would i get more job chances and better recognition?  Also thatnk you! i think i'm going with ubuntu 14
We cannot really know how many frontend/backend developer positions there are wherever you live.
I think that Frontend/Backend Devs are the best thing that happened to the community
What arduinos do you have, and what kind of projects do you use it for?  I only have an uno at the moment, but I've been fucking around with some LED matrices and it has been pretty fun.  I was looking into getting an Intel Galileo but apparently they're shit. Any opinions on it?
I've only ever done Pb-free, so I don't know how it feels. I'm sure it's less toxic, though.
I have an arduino uno, I use it as a remainder that I should use it, but it has also done a gret job laying around.
What other components do you have? I've found that finding the motivation to start a project is the hardest, but once you start it's really hard to stop. Make something fun.
Make a drone!   http://ardupilot.com/   https://en.wikipedia.org/wiki/Ardupilot   http://diydrones.com/notes/ArduPilot 
I have an Arduino Uno.  I played with it for a month, never made anything good with it.  Now it sits in a corner ;-;
